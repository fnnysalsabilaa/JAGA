{"cells":[{"cell_type":"code","execution_count":1,"id":"c671418d","metadata":{"id":"c671418d","executionInfo":{"status":"ok","timestamp":1653568299443,"user_tz":-420,"elapsed":7,"user":{"displayName":"Yohan Kristian M7011F1174","userId":"06042548635830738939"}}},"outputs":[],"source":["# Import standard dependencies\n","import cv2\n","import os\n","import uuid\n","import random\n","import numpy as np\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","execution_count":2,"id":"f375e2aa","metadata":{"id":"f375e2aa","executionInfo":{"status":"ok","timestamp":1653568302872,"user_tz":-420,"elapsed":3434,"user":{"displayName":"Yohan Kristian M7011F1174","userId":"06042548635830738939"}}},"outputs":[],"source":["# Import tensorflow dependencies - Functional API\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"id":"d4af4a41","metadata":{"id":"d4af4a41"},"outputs":[],"source":["# Avoid OOM errors by setting GPU Memory Consumption Growth\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus: \n","    tf.config.experimental.set_memory_growth(gpu, True)"]},{"cell_type":"code","execution_count":null,"id":"6d33213a","metadata":{"id":"6d33213a"},"outputs":[],"source":["os.makedirs('application_data')"]},{"cell_type":"code","execution_count":null,"id":"7176751b","metadata":{"id":"7176751b"},"outputs":[],"source":["# Setup paths\n","VER_PATH = os.path.join('application_data', 'verification_images')\n","INP_PATH = os.path.join('application_data', 'input_image')"]},{"cell_type":"code","execution_count":null,"id":"cc4457d1","metadata":{"id":"cc4457d1"},"outputs":[],"source":["# Make the directories\n","os.makedirs(VER_PATH)\n","os.makedirs(INP_PATH)"]},{"cell_type":"code","execution_count":null,"id":"869ebbc8","metadata":{"id":"869ebbc8"},"outputs":[],"source":["# Siamese L1 Distance class\n","class L1Dist(Layer):\n","    \n","    # Init method - inheritance\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","       \n","    # Magic happens here - similarity calculation\n","    def call(self, input_embedding, validation_embedding):\n","        return tf.math.abs(input_embedding - validation_embedding)"]},{"cell_type":"code","execution_count":null,"id":"c2adafed","metadata":{"id":"c2adafed"},"outputs":[],"source":["def preprocess(file_path):\n","    \n","    # Read in image from file path\n","    byte_img = tf.io.read_file(file_path)\n","    # Load in the image \n","    img = tf.io.decode_jpeg(byte_img)\n","    \n","    # Preprocessing steps - resizing the image to be 100x100x3\n","    img = tf.image.resize(img, (100,100))\n","    # Scale image to be between 0 and 1 \n","    img = img / 255.0\n","\n","    # Return image\n","    return img"]},{"cell_type":"code","execution_count":null,"id":"f010a9f7","metadata":{"id":"f010a9f7","outputId":"697f1ff8-9013-475b-9314-8b62e5cc879a"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}],"source":["# Reload model \n","siamese_model = tf.keras.models.load_model('siamesemodelv2_3.h5', \n","                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"]},{"cell_type":"markdown","id":"e7b2aab5","metadata":{"raw_mimetype":"text/html","id":"e7b2aab5"},"source":["Prepare to take picture for verification images Press P to Take a Picture, Press Q to exit module camera, 50 photos recommended"]},{"cell_type":"code","execution_count":null,"id":"8e1c1ada","metadata":{"id":"8e1c1ada"},"outputs":[],"source":["# Establish a connection to the webcam\n","cap = cv2.VideoCapture(0)\n","while cap.isOpened(): \n","    ret, frame = cap.read()\n","   \n","    # Cut down frame to 250x250px\n","    frame = frame[120:120+250,200:200+250, :]\n","    \n","    \n","    # Collect verification_images\n","    if cv2.waitKey(1) & 0XFF == ord('p'):\n","        # Create the unique file path \n","        imgname = os.path.join(VER_PATH, '{}.jpg'.format(uuid.uuid1()))\n","        # Write out verification images\n","        cv2.imwrite(imgname, frame)\n","    \n","    # Show image back to screen\n","    cv2.imshow('Image Collection', frame)\n","    \n","    # Breaking gracefully\n","    if cv2.waitKey(1) & 0XFF == ord('q'):\n","        break\n","        \n","# Release the webcam\n","cap.release()\n","# Close the image show frame\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"id":"19716e14","metadata":{"id":"19716e14","outputId":"3d853a34-a53e-4f29-acce-61af35e04ec9"},"outputs":[{"data":{"text/plain":["['0c9f5c27-dcef-11ec-914d-04d4c4734f75.jpg',\n"," '0cbf40cc-dcef-11ec-8f32-04d4c4734f75.jpg',\n"," '0cdc74d6-dcef-11ec-97d3-04d4c4734f75.jpg',\n"," '0cfbe450-dcef-11ec-91bc-04d4c4734f75.jpg',\n"," '0d1bf011-dcef-11ec-bea9-04d4c4734f75.jpg',\n"," '0d2f7861-dcef-11ec-b7c2-04d4c4734f75.jpg',\n"," '0d4cc50e-dcef-11ec-af6b-04d4c4734f75.jpg',\n"," '0d6c828b-dcef-11ec-9398-04d4c4734f75.jpg',\n"," '0d960463-dcef-11ec-98a1-04d4c4734f75.jpg',\n"," '0dbd1511-dcef-11ec-8095-04d4c4734f75.jpg',\n"," '0ddcf9bb-dcef-11ec-9f9c-04d4c4734f75.jpg',\n"," '0dfa1f33-dcef-11ec-a7ac-04d4c4734f75.jpg',\n"," '0e19dcf0-dcef-11ec-a0a9-04d4c4734f75.jpg',\n"," '0e399a67-dcef-11ec-bf6a-04d4c4734f75.jpg',\n"," '0e4f45b1-dcef-11ec-a5a9-04d4c4734f75.jpg',\n"," '0e6c923c-dcef-11ec-be94-04d4c4734f75.jpg',\n"," '0e8a2ceb-dcef-11ec-8f69-04d4c4734f75.jpg',\n"," '0eb3aebe-dcef-11ec-ac90-04d4c4734f75.jpg',\n"," '0ee6f4c0-dcef-11ec-9fa5-04d4c4734f75.jpg',\n"," '0f0e0568-dcef-11ec-ab3d-04d4c4734f75.jpg',\n"," '0f414b77-dcef-11ec-ab7b-04d4c4734f75.jpg',\n"," '0f6acd29-dcef-11ec-9f3e-04d4c4734f75.jpg',\n"," '0f944eee-dcef-11ec-bbf3-04d4c4734f75.jpg',\n"," '0fb19b81-dcef-11ec-82c6-04d4c4734f75.jpg',\n"," '0fdb6b6e-dcef-11ec-9203-04d4c4734f75.jpg',\n"," '10022e01-dcef-11ec-b91d-04d4c4734f75.jpg',\n"," '101a4a4d-dcef-11ec-ba35-04d4c4734f75.jpg',\n"," '1041a92e-dcef-11ec-a7a9-04d4c4734f75.jpg',\n"," '105ef5bd-dcef-11ec-b586-04d4c4734f75.jpg',\n"," '1072a535-dcef-11ec-b6bc-04d4c4734f75.jpg',\n"," '10923bb0-dcef-11ec-a4b1-04d4c4734f75.jpg',\n"," '10a5c414-dcef-11ec-bf5d-04d4c4734f75.jpg',\n"," '10c581b5-dcef-11ec-89ca-04d4c4734f75.jpg']"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["os.listdir(os.path.join('application_data', 'verification_images'))"]},{"cell_type":"code","execution_count":null,"id":"ee768e49","metadata":{"id":"ee768e49","outputId":"03b7f14e-697c-4be2-ad2c-8d43e66f4310"},"outputs":[{"data":{"text/plain":["'application_data\\\\input_image\\\\input_image.jpg'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["os.path.join('application_data', 'input_image', 'input_image.jpg')"]},{"cell_type":"code","execution_count":null,"id":"92f250db","metadata":{"id":"92f250db","outputId":"0ba5b297-53a7-4e3a-cc62-aeb66237222c"},"outputs":[{"name":"stdout","output_type":"stream","text":["application_data\\verification_images\\0c9f5c27-dcef-11ec-914d-04d4c4734f75.jpg\n","application_data\\verification_images\\0cbf40cc-dcef-11ec-8f32-04d4c4734f75.jpg\n","application_data\\verification_images\\0cdc74d6-dcef-11ec-97d3-04d4c4734f75.jpg\n","application_data\\verification_images\\0cfbe450-dcef-11ec-91bc-04d4c4734f75.jpg\n","application_data\\verification_images\\0d1bf011-dcef-11ec-bea9-04d4c4734f75.jpg\n","application_data\\verification_images\\0d2f7861-dcef-11ec-b7c2-04d4c4734f75.jpg\n","application_data\\verification_images\\0d4cc50e-dcef-11ec-af6b-04d4c4734f75.jpg\n","application_data\\verification_images\\0d6c828b-dcef-11ec-9398-04d4c4734f75.jpg\n","application_data\\verification_images\\0d960463-dcef-11ec-98a1-04d4c4734f75.jpg\n","application_data\\verification_images\\0dbd1511-dcef-11ec-8095-04d4c4734f75.jpg\n","application_data\\verification_images\\0ddcf9bb-dcef-11ec-9f9c-04d4c4734f75.jpg\n","application_data\\verification_images\\0dfa1f33-dcef-11ec-a7ac-04d4c4734f75.jpg\n","application_data\\verification_images\\0e19dcf0-dcef-11ec-a0a9-04d4c4734f75.jpg\n","application_data\\verification_images\\0e399a67-dcef-11ec-bf6a-04d4c4734f75.jpg\n","application_data\\verification_images\\0e4f45b1-dcef-11ec-a5a9-04d4c4734f75.jpg\n","application_data\\verification_images\\0e6c923c-dcef-11ec-be94-04d4c4734f75.jpg\n","application_data\\verification_images\\0e8a2ceb-dcef-11ec-8f69-04d4c4734f75.jpg\n","application_data\\verification_images\\0eb3aebe-dcef-11ec-ac90-04d4c4734f75.jpg\n","application_data\\verification_images\\0ee6f4c0-dcef-11ec-9fa5-04d4c4734f75.jpg\n","application_data\\verification_images\\0f0e0568-dcef-11ec-ab3d-04d4c4734f75.jpg\n","application_data\\verification_images\\0f414b77-dcef-11ec-ab7b-04d4c4734f75.jpg\n","application_data\\verification_images\\0f6acd29-dcef-11ec-9f3e-04d4c4734f75.jpg\n","application_data\\verification_images\\0f944eee-dcef-11ec-bbf3-04d4c4734f75.jpg\n","application_data\\verification_images\\0fb19b81-dcef-11ec-82c6-04d4c4734f75.jpg\n","application_data\\verification_images\\0fdb6b6e-dcef-11ec-9203-04d4c4734f75.jpg\n","application_data\\verification_images\\10022e01-dcef-11ec-b91d-04d4c4734f75.jpg\n","application_data\\verification_images\\101a4a4d-dcef-11ec-ba35-04d4c4734f75.jpg\n","application_data\\verification_images\\1041a92e-dcef-11ec-a7a9-04d4c4734f75.jpg\n","application_data\\verification_images\\105ef5bd-dcef-11ec-b586-04d4c4734f75.jpg\n","application_data\\verification_images\\1072a535-dcef-11ec-b6bc-04d4c4734f75.jpg\n","application_data\\verification_images\\10923bb0-dcef-11ec-a4b1-04d4c4734f75.jpg\n","application_data\\verification_images\\10a5c414-dcef-11ec-bf5d-04d4c4734f75.jpg\n","application_data\\verification_images\\10c581b5-dcef-11ec-89ca-04d4c4734f75.jpg\n"]}],"source":["for image in os.listdir(os.path.join('application_data', 'verification_images')):\n","    validation_img = os.path.join('application_data', 'verification_images', image)\n","    print(validation_img)"]},{"cell_type":"code","execution_count":null,"id":"fd856569","metadata":{"id":"fd856569"},"outputs":[],"source":["def verify(model, detection_threshold, verification_threshold):\n","    # Build results array\n","    results = []\n","    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n","        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n","        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n","        \n","        # Make Predictions \n","        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n","        results.append(result)\n","    \n","    # Detection Threshold: Metric above which a prediciton is considered positive \n","    detection = np.sum(np.array(results) > detection_threshold)\n","    \n","    # Verification Threshold: Proportion of positive predictions / total positive samples \n","    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images'))) \n","    verified = verification > verification_threshold\n","    \n","    return results, verified"]},{"cell_type":"markdown","id":"3a2edcc2","metadata":{"id":"3a2edcc2"},"source":["Press V to Verif your Face, Please wait, it might not responding"]},{"cell_type":"code","execution_count":null,"id":"b8a6c3ba","metadata":{"id":"b8a6c3ba","outputId":"e9be2c85-51b8-449d-af47-d61733ada426"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 4s 4s/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","True\n"]}],"source":["cap = cv2.VideoCapture(0)\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    frame = frame[120:120+250,200:200+250, :]\n","    \n","    cv2.imshow('Verification', frame)\n","    \n","    # Verification trigger\n","    if cv2.waitKey(10) & 0xFF == ord('v'):\n","        # Save input image to application_data/input_image folder \n","#         hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","#         h, s, v = cv2.split(hsv)\n","\n","#         lim = 255 - 10\n","#         v[v > lim] = 255\n","#         v[v <= lim] -= 10\n","        \n","#         final_hsv = cv2.merge((h, s, v))\n","#         img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n","\n","        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n","        # Run verification\n","        results, verified = verify(siamese_model, 0.5, 0.5)\n","        print(verified)\n","    \n","    if cv2.waitKey(10) & 0xFF == ord('q'):\n","        break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","id":"39d30698","metadata":{"id":"39d30698"},"source":["If True, than it is your face. You can repeatly press V and see the result"]},{"cell_type":"code","execution_count":null,"id":"fcc84164","metadata":{"id":"fcc84164","outputId":"c870dc13-08cd-429e-9b4b-4f1c2c8cea8d"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["np.sum(np.squeeze(results) > 0.9)"]},{"cell_type":"markdown","id":"bfdaba01","metadata":{"id":"bfdaba01"},"source":["The similarity between input image and verification images"]},{"cell_type":"code","execution_count":null,"id":"638ac757","metadata":{"id":"638ac757","outputId":"ad8517ad-1c49-4b0d-8efd-0cb0474d363d"},"outputs":[{"data":{"text/plain":["[array([[0.4731445]], dtype=float32),\n"," array([[0.51513034]], dtype=float32),\n"," array([[0.53998864]], dtype=float32),\n"," array([[0.4249946]], dtype=float32),\n"," array([[0.5352235]], dtype=float32),\n"," array([[0.57268184]], dtype=float32),\n"," array([[0.52879727]], dtype=float32),\n"," array([[0.48781744]], dtype=float32),\n"," array([[0.4871508]], dtype=float32),\n"," array([[0.5089126]], dtype=float32),\n"," array([[0.5284216]], dtype=float32),\n"," array([[0.47070253]], dtype=float32),\n"," array([[0.5610992]], dtype=float32),\n"," array([[0.40965617]], dtype=float32),\n"," array([[0.5944291]], dtype=float32),\n"," array([[0.50662005]], dtype=float32),\n"," array([[0.52387077]], dtype=float32),\n"," array([[0.5321413]], dtype=float32),\n"," array([[0.65611976]], dtype=float32),\n"," array([[0.3754235]], dtype=float32),\n"," array([[0.6443697]], dtype=float32),\n"," array([[0.8215317]], dtype=float32),\n"," array([[0.7034267]], dtype=float32),\n"," array([[0.847939]], dtype=float32),\n"," array([[0.726975]], dtype=float32),\n"," array([[0.5067177]], dtype=float32),\n"," array([[0.514882]], dtype=float32),\n"," array([[0.50686896]], dtype=float32),\n"," array([[0.4471935]], dtype=float32),\n"," array([[0.43796298]], dtype=float32),\n"," array([[0.46739867]], dtype=float32),\n"," array([[0.5305689]], dtype=float32),\n"," array([[0.5804036]], dtype=float32)]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["results"]},{"cell_type":"code","execution_count":null,"id":"b5aec8ca","metadata":{"id":"b5aec8ca"},"outputs":[],"source":[""]}],"metadata":{"celltoolbar":"Raw Cell Format","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"name":"Demo.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}